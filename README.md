# 爬取目标
## 正文
- 日期
- 时间
- 昵称
- 发布来源
- 微博内容
- 点赞数
- 评论数
- 转发数
- 评论采集链接

## 评论
- 评论内容
- 评论者昵称
- 评论发布日期

## 每条微博目前只能爬取50页评论

# 爬取思路
1. 首先爬取每条微博的`正文`内容以及评论链接(`crawl_link.py`)
2. 爬取每条微博对应的评论(`crawl_comment.py`)
3. 配置项见 `config.py`
4. 上述思路可以抽象为一个生产者-消费者模式，后续有时间的话进行代码重构

# FAQ
- 高级搜索功能需要用户登录，因此采取的策略是先用个人账号登录，然后保存 `cookie`
- 微博的评论是通过下拉滚动条来完成加载的，如果评论数量过多，会出现 `加载更多` 按钮。上述两种行为虽然可以通过 [selenium](https://www.selenium.dev/selenium/docs/api/py/) 来模拟，但过程较为繁琐，不推荐。幸运的是，微博评论还保有老版链接，例如 `https://weibo.cn/comment/{weibo_id}?page={page_number}`，通过请求这个接口来获取评论html页面，然后解析
